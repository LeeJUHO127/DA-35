{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23870109-6d31-4db7-b782-b699fe671867",
   "metadata": {},
   "source": [
    "# GRU(Gated Recurrent Units) 모델\n",
    "- https://arxiv.org/pdf/1406.1078\n",
    "- LSTM이 RNN의 한계점인 기억력 소실문제를 해결하여 긴 sequence의 데이터에서도 좋은 성능을 내는 모델이다. 그러나 복잡한 구조로 parameter가 많아지게 되었고 연산량이 많은 문제점이 있다.\n",
    "    - parameter가 많아지면서 데이터양이 부족할 경우 과대적합이 발생하고 연산량이 많아 학습에 많은 시간이 걸리게 된다.\n",
    "- LSTM의 이런 문제를 개선하기 위한 변형 모델이 GRU이다.\n",
    "\n",
    "## LSTM과 차이\n",
    "1. LSTM은 forget gate, input gate, output gete 세개의 Gate연산을 함. GRU는 **reset get와 update gate** 로 흐름을 제어한다.\n",
    "2. LSTM은 이전 처리결과로 Cell State, Hidden State 두개가 있었는데 이것을 하나로 합쳐 **Hidden State**로 출력한다.\n",
    "\n",
    "## GRU 성능\n",
    "- GRU는 적은 파라미터 수와 연산비용이 적게 드는 것에 비해 LSTM과 비슷한 성능을 내는 것으로 알려졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18729a02-f014-4082-826f-824b9d7adbf6",
   "metadata": {},
   "source": [
    "## GRU Cell 구조\n",
    "\n",
    "![gru_cell](figures/rnn/23_gru_cell.png)    \n",
    "[이미지 Source](https://www.oreilly.com/library/view/advanced-deep-learning/9781789956177/8ad9dc41-3237-483e-8f6b-7e5f653dc693.xhtml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9740062-d77e-4b55-946d-4135af3c8e28",
   "metadata": {},
   "source": [
    "- **Reset Gate**\n",
    "    - 이전 timestep의 hidden state값을 현재 timestep의 hidden state 계산시 얼마나 반영할 지를 결정하는 gate\n",
    "    - $r_{t} = \\sigma(h_{t-1}\\cdot U_{r} + X_{t}\\cdot W_{r})$\n",
    "        - $U_{r},\\, W_{r}$ 는 파라미터\n",
    "        - $\\sigma$: sigmoid(logisic) 함수\n",
    "- **Update Gate**\n",
    "    - 현재 timestep의 hidden state($h_t$)를 계산할 때 이전 time step까지 정보($h_{t-1}$)와 현재 time step의 정보($X_t$)를 각각 얼마나 반영할지 비율을 정의한다.\n",
    "    - $z_{t} = \\sigma(h_{t-1}\\cdot U_{z} + X_{t}\\cdot W_{z})$\n",
    "        - $U_{z},\\, W_{z}$ 는 파라미터\n",
    "        - $\\sigma$: sigmoid(logisic) 함수\n",
    "    - $h_t$를 계산할 때 $z_{t}$ 는 이전 정보인 $h_{t-1}$을 얼마나 반영할지 $1-z_{t}$는 현재 정보를 얼마나 반영할 지를 정한다.\n",
    "- **Cell의 출력값인 $h_t$ 계산**\n",
    "    - $z_{t}\\times h_{t-1} + tanh(h_{t-1} * r_{t}+X_{t}\\cdot W)\\times(1-z_{t})$\n",
    "    - 이전 정보에는 $z_t$를 곱해 얼마나 $h_t$ 에 더할지 연산\n",
    "    - 현재 정보($X_t$)에는 이전 정보를 일부를 반영한다. 이전 정보를 얼마나 반영할지를 reset gate 결과를 곱해 결정한다. 활성화 함수 tanh를 이용해 비선형성을 추가 한 결과에 $1-z_t$를 곱한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c6f7c4-0cfb-4ac8-b7dd-834a44c18880",
   "metadata": {},
   "source": [
    "## Pytorch GRU\n",
    "- `nn.GRU` 클래스 이용\n",
    "    - https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
    "- **입력**\n",
    "    - **input**: (seq_length, batch, hidden_size) shape의 tensor. (batch_first=False), batch_first=True이면 `seq_length`와 `batch` 위치가 바뀐다.\n",
    "    - **hidden**: (D * num_layers, batch, hidden_size) shape의 Tensor. D(양방향:2, 단방향:1), hidden은 생략하면 0이 입력됨.\n",
    "- **출력** - output과 hidden state가 반환된다.\n",
    "    - **output**\n",
    "        - 모든 sequence의 처리결과들을 모아서 제공.\n",
    "        - shape: (seq_length, batch, D * hidden_size) : D(양방향:2, 단방향:1), batch_first=True이면 `seq_length`와 `batch` 위치가 바뀐다.\n",
    "    - **hidden**\n",
    "        - 마지막 time step 처리결과\n",
    "        - shape: (D * num_layers, batch, hidden) : D(양방향:2, 단방향:1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f6469b-dfea-4482-8789-8c34363752cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_data = torch.randn((20, 2, 10))   # [seq_len,  batch_size,  input_size] (float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0180b8b7-01d7-4bca-bb82-370abea3ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru1 = nn.GRU(\n",
    "    input_size=10, \n",
    "    hidden_size=30    #num_layers=1, bd=False, batch_first=False\n",
    ")\n",
    "o1, h1 = gru1(input_data)  # input, hidden(생략=>0, 첫번째 timestep의 hidden)\n",
    "print(o1.shape)  # 모든 timestep의 처리결과를 묶어서 반환. [seq_len, batch, hidden_size*D]\n",
    "print(h1.shape)  # 마지막 timestep의 처리결과. 방향별, layer별 hidden state값을 묶어서 제공.\n",
    "#  [D * num_layers,   batch, hidden_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f48e2d-93ed-47ab-9bf7-22f19d3bac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gru2 = nn.GRU(\n",
    "    input_size=10, \n",
    "    hidden_size=30, \n",
    ")\n",
    "o2, h2 = gru2(input_data, h1)  # input, hidden (앞 GRU의 hidden을 다음 GRU에 입력)\n",
    "print(o2.shape)  # 모든 timestep의 처리결과를 묶어서 반환. [seq_len, batch, hidden_size*D]\n",
    "print(h2.shape)  # 마지막 timestep의 처리결과. 방향별, layer별 hidden state값을 묶어서 제공.\n",
    "#  [D * num_layers,   batch, hidden_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d86e6-0a72-4fde-9e57-51417b1ed782",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru3 = nn.GRU(\n",
    "    input_size=10, \n",
    "    hidden_size=30 ,\n",
    "    num_layers=3,\n",
    "    bidirectional=True\n",
    ")\n",
    "o3, h3 = gru3(input_data)  # input, hidden(생략=>0)\n",
    "print(o3.shape)  # 모든 timestep의 처리결과를 묶어서 반환. [seq_len, batch, hidden_size*2]\n",
    "print(h3.shape)  # 마지막 timestep의 처리결과. 방향별, layer별 hidden state값을 묶어서 제공.\n",
    "#  [1* 3,   batch, hidden_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794b0319-660e-42f0-a390-6ec71ade0b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b5bac-e226-40e3-9e8c-96e3cf9ad9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8389555c-17d0-41ed-abfc-42046bf8aeaa",
   "metadata": {},
   "source": [
    "# Encoder-Decoder 구조\n",
    "- 두개의 네트워크를 연결한 구조\n",
    "- Encoder network는 입력을 이해하고 Decoder network는 (Encoder의 이해를 바탕으로) 출력을 생성한다.\n",
    "\n",
    "## Seq2Seq\n",
    "- Encoder-Decoder 구조를 RNN 계열에 적용한 모델.\n",
    "- Encoder는 입력 Sequence의 전체 의미(특징)을 표현하는 **context vector**를 출력한다.\n",
    "    - **Context Vector는**\n",
    "        - 번역의 경우 번역할 대상 문장에서 **번역 결과를 만들때 필요한 feature들**을 가지고 있다.\n",
    "        - Chatbot의 경우 입력된 질문에서 **답변을 만들때 필요한 feature들**을 가지고 있다.\n",
    "- Decoder는 Encoder가 출력한 Context Vector를 입력받아 결과 sequence를 생성한다.\n",
    "    - **결과 sequence는**\n",
    "        - **번역**의 경우 번역 문장을 생성한다.\n",
    "        - **chatbot**의 경우 질문에 대한 답변을 생성한다.\n",
    "\n",
    "![seq2seq](figures/seq2seq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9887d108-2ac6-425e-9643-d351e44282c7",
   "metadata": {},
   "source": [
    "# Seq2Seq 를 이용한 Chatbot 모델 구현\n",
    "- Encoder를 이용해 질문의 특성을 추출하고 Decoder를 이용해 답변을 생성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec7aee-1d3b-4990-b934-a4254a6e17ef",
   "metadata": {},
   "source": [
    "# Chatbot Dataset\n",
    "\n",
    "- https://github.com/songys/Chatbot_data\n",
    "- columns\n",
    "    - Q: 질문\n",
    "    - A: 답\n",
    "    - label: 일상다반사 0, 이별(부정) 1, 사랑(긍정) 2\n",
    "- **Download**\n",
    "\n",
    "![dataset](figures/chatbot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa75cf8-9cd9-4a72-a610-4392b80ca6b5",
   "metadata": {},
   "source": [
    "# Chatbot Dataset Loading 및 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbd0c3c-2b8f-4a4c-b90c-a0fa6d828c4c",
   "metadata": {},
   "source": [
    "## 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ed2c29e-1aef-48c3-87ba-a89cc8ed6146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 3)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"datasets/ChatbotData.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db7a1399-e014-42f0-b839-0cfc9a1eb218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fc98856-b66d-4e2e-bc8a-27e3d34dcfd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=\"label\", inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f36158c3-3848-4b8a-a238-0f828688dae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A\n",
       "0           12시 땡!   하루가 또 가네요.\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.\n",
       "4          PPL 심하네   눈살이 찌푸려지죠."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de7d800f-5cc4-4a93-8fd9-9bf865c65b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "646f915c-6f54-4694-a8b3-3efd10fff5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q    0\n",
       "A    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aad072-2245-41e8-9863-a0b451262fdd",
   "metadata": {},
   "source": [
    "# Dataset, DataLoader 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e0b8d-ee13-488b-ae6e-2a7d4189fd6c",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "### Subword방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d080f3aa-6d49-464f-9469-91ef9bcd351c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23646, 11823, 11823)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 질문 문장 + 답변 문장 => tokenizer 객체를 생성.\n",
    "question_texts = list(df['Q'])  # list(Series)\n",
    "answer_texts = list(df['A'])\n",
    "all_texts = question_texts + answer_texts\n",
    "len(all_texts), len(question_texts), len(answer_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae144ea5-9f2a-4232-a929-da7f3497f7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12시 땡!', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d60742d6-dea5-430a-a030-369a07b0b169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "vocab_size = 30000\n",
    "min_frequency = 2\n",
    "\n",
    "tokenizer = Tokenizer(\n",
    "    BPE(unk_token='[UNK]')  # Unknow Token(Out Of Vocabulary) - 어휘사전에 없는 단어.\n",
    ")\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "trainer = BpeTrainer(  # 학습 방식을 설정.\n",
    "    vocab_size=vocab_size,\n",
    "    min_frequency=min_frequency, \n",
    "    special_tokens=[\"[PAD]\", \"[UNK]\", \"[SOS]\", \"[EOS]\"], \n",
    "    continuing_subword_prefix=\"#\", \n",
    "    # 단어 중간에 사용된 subword일 경우 앞에 붙일 표시특수문자.\n",
    "    #   돌부처 => 돌, #부처    부처님 => 부처, #님\n",
    ")\n",
    "# 학습 \n",
    "##  Dataset이 메모리에 있는 경우. [\"문서\", \"문서\", \"문서\",  ......]\n",
    "tokenizer.train_from_iterator(all_texts, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "191bad62-e367-410f-84be-77883ad334ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총어휘수: 15579\n",
      "['내일은', '즐거운', '주말', '#입니다', '.']\n",
      "[3842, 3272, 2806, 2467, 9]\n",
      "내일은\n",
      "3842\n",
      "8871 2467\n"
     ]
    }
   ],
   "source": [
    "print(\"총어휘수:\", tokenizer.get_vocab_size())\n",
    "encode = tokenizer.encode(\"내일은 즐거운 주말입니다.\")\n",
    "print(encode.tokens)\n",
    "print(encode.ids)\n",
    "print(tokenizer.id_to_token(3842))\n",
    "print(tokenizer.token_to_id('내일은'))\n",
    "print(tokenizer.token_to_id('입니다'), tokenizer.token_to_id('#입니다'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd35be3d-4728-4de4-8f60-e22d6c0dcc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.token_to_id(\"[PAD]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80caf0b3-01d5-4631-87c1-f48ab2f5bafc",
   "metadata": {},
   "source": [
    "### Tokenizer 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5170048b-bb11-49d2-b295-2471b78d83f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models/tokenizers', exist_ok=True)\n",
    "tk_path = 'models/tokenizers/chatbot_data_bpe.json'\n",
    "tokenizer.save(tk_path)\n",
    "\n",
    "# 로딩\n",
    "## load_tokenizer = Tokenizer.from_file(tk_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b068c-ead0-4f75-bd01-4a0ebf486774",
   "metadata": {},
   "source": [
    "## Dataset, DataLoader 정의\n",
    "\n",
    "\n",
    "### Dataset 정의 및 생성\n",
    "- 모든 문장의 토큰 수는 동일하게 맞춰준다.\n",
    "    - DataLoader는 batch 를 구성할 때 batch에 포함되는 데이터들의 shape이 같아야 한다. 그래야 하나의 batch로 묶을 수 있다.\n",
    "    - 문장의 최대 길이를 정해주고 **최대 길이보다 짧은 문장은 `<PAD>` 토큰을 추가**하고 **최대길이보다 긴 문장은 최대 길이에 맞춰 짤라준다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ae89444-25b0-4b96-819a-640e35d933dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler\n",
    "from torch import optim\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d181d3a2-a7eb-482a-8c9e-b03feaca8f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set[0]  => (x[0]-질문,  y[0]-답변)\n",
    "# x, y -> 토큰_id 리스트.  [3842, 3271, 2806, 2467, 9, PAD, PAD, ...]\n",
    "class ChatbotDataset(Dataset):\n",
    "    \"\"\"\n",
    "    ChatbotDataset\n",
    "    Attribute\n",
    "        question_texts: list[str] - 질문 texts 목록. 리스트에 질문들을 담아서 받는다. [\"질문1\", \"질문2\", ...]\n",
    "        answer_texts: list[str] - 답 texts 목록. 리스트에 답변들을 담아서 받는다.     [\"답1\", \"답2\", ...]\n",
    "        max_length: 개별 댓글의 token 개수. 모든 댓글의 토큰수를 max_length에 맞춘다.\n",
    "        tokenizer: Tokenizer\n",
    "        vocab_size: int 총단어수\n",
    "        PAD_TOKEN: int Padding 토큰 id\n",
    "    \"\"\"\n",
    "    def __init__(self, question_texts, answer_texts, max_length, tokenizer):\n",
    "        \"\"\"\n",
    "        Parameter\n",
    "            question_texts: list[str] - 질문 texts 목록. 리스트에 질문들을 담아서 받는다. [\"질문1\", \"질문2\", ...]\n",
    "            answer_texts: list[str] - 답 texts 목록. 리스트에 답변들을 담아서 받는다.     [\"답1\", \"답2\", ...]\n",
    "            max_length: 개별 댓글의 token 개수. 모든 댓글의 토큰수를 max_length에 맞춘다.\n",
    "            tokenizer: Tokenizer\n",
    "        \"\"\"\n",
    "        self.question_texts = question_texts\n",
    "        self.answer_texts = answer_texts\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        self.vocab_size = tokenizer.get_vocab_size()\n",
    "        self.PAD_TOKEN = self.tokenizer.token_to_id(\"[PAD]\")\n",
    "    \n",
    "    def __pad_token_sequence(self, token_sequence):\n",
    "        \"\"\"\n",
    "        max_length 길이에 맞춰 token_id 리스트를 구성한다.\n",
    "        max_length 보다 길면 뒤에를 자르고 max_length 보다 짧으면 [PAD] 토큰을 추가한다.\n",
    "        \n",
    "        Parameter\n",
    "            token_sentence: list[int] - 길이를 맞출 한 문장 token_id 목록\n",
    "        Return\n",
    "            list[int] - length가 max_length인 token_id 목록\n",
    "        \"\"\"\n",
    "        seq_len = len(token_sequence)\n",
    "        token_ids = None\n",
    "        if seq_len >= self.max_length: # 크면 자르기\n",
    "            token_ids = token_sequence[:self.max_length]\n",
    "        else: # 적으면 PAD 추가.\n",
    "            token_ids = token_sequence + ([self.PAD_TOKEN] * (self.max_length - seq_len))\n",
    "        return token_ids\n",
    "        \n",
    "    def __process_sequence(self, text):\n",
    "        \"\"\"\n",
    "        한문장을 받아서 padding이 추가된 token_id 리스트로 변환 후 반환\n",
    "        Parameter\n",
    "            text: str - token_id 리스트로 변환할 한 문장\n",
    "        Return\n",
    "            list[int] - 입력받은 문장에 대한 token_id 리스트\n",
    "        \"\"\"\n",
    "        # 문장 -> encoding\n",
    "        encode = self.tokenizer.encode(text)\n",
    "        # encode.ids의 크기를 max_length에 맞춘다. \n",
    "        token_ids = self.__pad_token_sequence(encode.ids) # [ 30, 20, 10] => [30, 20, 10, 0, 0, ..]\n",
    "        return token_ids\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.question_texts)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # index의 question, anwser token_id_리스트를 묶어서 반환.\n",
    "        question = self.question_texts[index]  # string\n",
    "        answer = self.answer_texts[index]\n",
    "\n",
    "        # encoding+padding 처리된 token_id_list: list 생성.\n",
    "        # \"학교는 어디있나요?\"  ==> [2000, 323, 2131, 3908, ...]\n",
    "        question_token_ids = self.__process_sequence(question) \n",
    "        answer_token_ids = self.__process_sequence(answer)\n",
    "\n",
    "        return torch.LongTensor(question_token_ids), torch.LongTensor(answer_token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eef9908e-9d13-49bf-9834-d7951fade6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15579\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "MAX_LENGTH = 25\n",
    "tokenizer = Tokenizer.from_file('models/tokenizers/chatbot_data_bpe.json')\n",
    "\n",
    "dataset = ChatbotDataset(question_texts, answer_texts, MAX_LENGTH, tokenizer)\n",
    "print(dataset.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c7c5a77-d1ea-44a6-92fe-8e83b0c4336b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70024949-e479-4780-8343-e23607d9e5dd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25]) tensor([13130,  4368,   810,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0])\n",
      "torch.Size([25]) tensor([5679, 4783,   77, 2447,    9,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0])\n"
     ]
    }
   ],
   "source": [
    "a, b = dataset[110]\n",
    "print(a.shape, a)\n",
    "print(b.shape, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6d2b6f-ccf7-4aec-9c08-176a2456e813",
   "metadata": {},
   "source": [
    "### Trainset / Testset 나누기\n",
    "train : test = 8 : 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c724437b-1e83-4173-bfec-9e4117935a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb7d0d5a-c8ba-48be-bc46-d5ba12cd89e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9458 2365\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(dataset) * 0.8)\n",
    "test_size = len(dataset) - train_size\n",
    "print(train_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e4125b9-6e3d-4522-97ce-d55ad427acf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9458, 2365)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, test_set = random_split(dataset, [train_size, test_size])\n",
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4b274f-8c8a-4aa6-af6d-a66bf5c38210",
   "metadata": {},
   "source": [
    "### DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c51e1123-cbdd-4dce-8998-d4638ce04e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147, 37)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE)\n",
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b24fc-7bd3-44ca-8abb-1e1a16a7aae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cdaf424-c7de-46be-b74b-88a3efcdf352",
   "metadata": {},
   "source": [
    "# 모델 정의\n",
    "\n",
    "## Seq2Seq 모델 정의\n",
    "- Seq2Seq 모델은 Encoder와 Decoder의 입력 Sequence의 길이와 순서가 자유롭기 때문에 챗봇이나 번역에 이상적인 구조다.\n",
    "    - 단일 RNN은 각 timestep 마다 입력과 출력이 있기 때문에 입/출력 sequence의 개수가 같아야 한다.\n",
    "    - 챗봇의 질문/답변이나 번역의 대상/결과 문장의 경우는 사용하는 어절 수가 다른 경우가 많기 때문에 단일 RNN 모델은 좋은 성능을 내기 어렵다.\n",
    "    - Seq2Seq는 **입력처리(질문,번역대상)처리 RNN과 출력 처리(답변, 번역결과) RNN 이 각각 만들고 그 둘을 연결한 형태로 길이가 다르더라도 상관없다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d7410-a73e-4be1-b41d-9ea07d6b0911",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "Encoder는 하나의 Vector를 생성하며 그 Vector는 **입력 문장의 의미**를 N 차원 공간 저장하고 있다. 이 Vector를 **Context Vector** 라고 한다.    \n",
    "![encoder](figures/seq2seq_encoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1074b70f-23d6-433b-a29c-cd242e693294",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.token_to_id(\"[PAD]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a005e01d-1afc-4575-a506-6c5bfa78fe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embedding_dim, \n",
    "                   num_layers=1, bidirectional=False, dropout_rate=0.0):\n",
    "        super().__init__()\n",
    "        # 어휘수 저장.\n",
    "        self.vocab_size = vocab_size\n",
    "        #Embedding Layer 생성\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size,      #어휘사전의 총 단어수\n",
    "            embedding_dim=embedding_dim, # 단어 임베딩 벡터의 차원수(몇개 숫자로 구성 할지)\n",
    "            padding_idx=0\n",
    "        )\n",
    "        # GRU\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=embedding_dim, \n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout_rate,     # dropout=(0.0 if num_layers==1 else dropout_rate)\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        embedding = self.embedding(X)\n",
    "        # (batch, seq, 임베딩차원)\n",
    "        embedding = embedding.permute(1, 0, 2)\n",
    "        # gru\n",
    "        output, hidden = self.gru(embedding)  \n",
    "        # output: 모든 timestep의 hidden state들. hidden: 마지막 timestep의 hidden state\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff60f00e-707c-47e9-ab60-dad42d0ec508",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.get_vocab_size()\n",
    "embedding_dims = 100\n",
    "hidden_size = 256\n",
    "bidir = True\n",
    "\n",
    "a, b = next(iter(train_loader))  # a: Q, b: A\n",
    "e = Encoder(vocab_size=vocab_size, \n",
    "            embedding_dim=embedding_dims, \n",
    "            hidden_size=hidden_size, \n",
    "            bidirectional=bidir)\n",
    "o1, h1 = e(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac57149a-87fe-4cfa-9cb9-5b3c2f6da7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 25])\n",
      "torch.Size([64, 25])\n"
     ]
    }
   ],
   "source": [
    "print(a.shape) # [64, 25] -> [batch_size, seq_length]\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b7c9fcf-6d84-4c2f-b7b5-82ea92b80150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 64, 512])\n",
      "torch.Size([2, 64, 256])\n"
     ]
    }
   ],
   "source": [
    "print(o1.shape) # [25, 64, 512] -> [seq_length, batch_size, hidden_state * 양방향(2)]\n",
    "print(h1.shape) # [2, 64, 256]  -> [양방향(2) *  num_layers(1),  batch_size,  hidden_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24779603-15ac-4ba1-a24c-6e86658b3ad6",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "- Encoder의 출력(context vector)를 받아서 번역 결과 sequence를 출력한다.\n",
    "- Decoder는 매 time step의 입력으로 **이전 time step에서 예상한 단어와 hidden state값이** 입력된다.\n",
    "- Decoder의 처리결과 hidden state를 Estimator(Linear+Softmax)로 입력하여 **입력 단어에 대한 번역 단어가 출력된다.** (이 출력단어가 다음 step의 입력이 된다.)\n",
    "    - Decoder의 첫 time step 입력은 문장의 시작을 의미하는 <SOS>(start of string) 토큰이고 hidden state는 context vector(encoder 마지막 hidden state) 이다.\n",
    "\n",
    "![decoder](figures/seq2seq_decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d59f484-0ec6-4489-ba4c-23e31cfac833",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, embedding_dim, num_layers=1,\n",
    "                   dropout_rate=0):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        # GRU - 생성 => 스스로 만든 단어를 다음 step의 입력 --> 단방향 RNN\n",
    "        self.gru = nn.GRU(\n",
    "            embedding_dim, \n",
    "            hidden_size, \n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout_rate     # dropout=(0 if num_layer==1 else dropout_rate)\n",
    "        )\n",
    "        ## 입력에 대해서 예측한 다음 입력 단어\n",
    "        ### gru: output -> (seq_len: 1, batch, hidden_size*단방향)\n",
    "        self.classifier = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, X, hidden_state):\n",
    "        \"\"\"\n",
    "        이전 생성 단어와 이전 step까지의 hidden_state를 입력 받아 다음 단어를 생성한다.\n",
    "        X: 이전 처리단어의 token. 첫번째 time step에서는 [SOS] 문장시작 token을 받는다.\n",
    "        Parameter:\n",
    "            X: torch.Tensor - long(64bit) or int(32bit) type Tensor, Token list, shape - [batch]. seq_length는 1 (한글자씩 입력된다.)\n",
    "            hidden_state: torch.Tensor - Float. 첫번째 timestep의 경우 Encoder의 hidden state\n",
    "                                                        두번째 timestep 부터는 이전 처리 결과.\n",
    "                                                        shape: [1, batch, hidden_state] seq_len: 1 - 한개 토큰씩 처리.\n",
    "        Return\n",
    "            tuple - 분류결과, hidden_state(RNN 마지막 step 처리결과)  \n",
    "                    분류결과: 생성할 단어(토큰)의 확률\n",
    "                    hidden_state: 다음 sequence 처리의 hidden state로 입력.\n",
    "        \"\"\"\n",
    "        # X.shape : [batch] - [64]  한개 토큰만 입력\n",
    "        X = X.unsqueeze(1)  # [64] =>  [64, 1 :seq_len]   # [batch] -> [batch, 1]\n",
    "        embedding = self.embedding(X).permute(1, 0, 2)\n",
    "        # embedding:  [64, 1, 100] [batch_size, seq_len, embedding_dim]\n",
    "        #    embedding 결과를 GRU에 입력하기 위해 batch_size <->seq_len \n",
    "\n",
    "        out = self.dropout(embedding)\n",
    "        \n",
    "        output, hidden = self.gru(out, hidden_state)\n",
    "        ## 마지막 timestep의 처리결과를 Linear에 입력\n",
    "        # output shape: [seq_len: 1, batch, hidden_size]\n",
    "        last_out = output[-1, : , :]  # [1, 64, 256] =조회결과=> [64, 256]\n",
    "        last_out = self.classifier(last_out)\n",
    "        return last_out, hidden  # 다음단어, 현재 처리 feature(gru 반환 hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "282f60e8-7e86-479a-8522-d32aab86b1b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = Decoder(vocab_size, hidden_size * 2,  # encoder hidden state 크기  (양방향-hs * 2)\n",
    "                 embedding_dims)\n",
    "i = torch.ones(size=(64, ), dtype=torch.long)# 첫번째 토큰\n",
    "# print(o1[-1].shape, i.shape) \n",
    "o1[-1, :, :].unsqueeze(0).shape  # 25 seq에서 마지막 seq 조회. seq_length dummy axis를 추가.\n",
    "o2, h2 = d(i, o1[-1, :, :].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "722be9ac-4db1-4dda-a7dd-6e12d471b084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.3608, 0.2930], grad_fn=<TopkBackward0>),\n",
       "indices=tensor([11874,   333]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o2.shape # [batch_size, 어휘시]\n",
    "o2[1].topk(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dbb1cd25-b1e6-4f64-9319-e397561845ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[0.3608, 0.2930, 0.2531],\n",
       "        [0.3608, 0.2930, 0.2531]], grad_fn=<TopkBackward0>),\n",
       "indices=tensor([[11874,   333,  3170],\n",
       "        [11874,   333,  3170]]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o2.shape\n",
    "# o2.argmax(-1)\n",
    "o2[:2].topk(3)   # Tensor 원소중 가장 큰값 순서대로 1개 의 값과 index를 반환.\n",
    "# 가장 큰값 top k개를 반환. (값, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b73dc604-26fb-4e4d-836c-8ee1a6c14505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'팀워 둠 친구한테'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.id_to_token(11874)\n",
    "tokenizer.decode([11874,   333,  3170])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2bf3f0f4-309f-4b74-a13a-a52a82a07b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3],\n",
       "        [10,  2,  5]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "875be45b-61cf-4920-b13b-56de83b0ed1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[ 3,  2],\n",
       "        [10,  5]]),\n",
       "indices=tensor([[2, 1],\n",
       "        [0, 2]]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(\n",
    "    [\n",
    "        [1, 2, 3], \n",
    "        [10, 2, 5]\n",
    "    ]) \n",
    "\n",
    "a.topk(k=2)  # 가장 큰값  k개 조회. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52cdf137-057b-4e41-95cd-c58219032b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 512])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3563f5b2-f18b-42b5-9bd4-f4f8abd767ac",
   "metadata": {},
   "source": [
    "## Seq2Seq 모델\n",
    "\n",
    "- Encoder - Decoder 를 Layer로 가지며 Encoder로 질문의 feature를 추출하고 Decoder로 답변을 생성한다.\n",
    "\n",
    "### Teacher Forcing\n",
    "- **Teacher forcing** 기법은, RNN계열 모델이 다음 단어를 예측할 때, 이전 timestep에서 예측된 단어를 입력으로 사용하는 대신 **실제 정답 단어(ground truth) 단어를** 입력으로 사용하는 방법이다.\n",
    "    - 모델은 이전 시점의 출력 단어를 다음 시점의 입력으로 사용한다. 그러나 모델이 학습할 때 초반에는 정답과 많이 다른 단어가 생성되어 엉뚱한 입력이 들어가 학습이 빠르게 되지 않는 문제가 있다.\n",
    "- **장점**\n",
    "    - **수렴 속도 증가**: 정답 단어를 사용하기 때문에 모델이 더 빨리 학습할 수있다.\n",
    "    - **안정적인 학습**: 초기 학습 단계에서 모델의 예측이 불안정할 때, 잘못된 예측으로 인한 오류가 다음 단계로 전파되는 것을 막아줍니다.\n",
    "- **단점**\n",
    "    - **노출 편향(Exposure Bias) 문제:** 실제 예측 시에는 정답을 제공할 수 없으므로 모델은 전단계의 출력값을 기반으로 예측해 나가야 한다. 학습 과정과 추론과정의 이러한 차이 때문에 모델의 성능이 떨어질 수있다.\n",
    "        - 이런 문제를 해결하기 학습 할 때 **Teacher forcing을 random하게 적용하여 학습시킨다.**\n",
    "![seq2seq](figures/seq2seq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "64d3e1ea-b8c7-4e29-bb05-643f9257a113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.token_to_id('[SOS]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e5c6609-7765-43f4-935b-47e3fa22c060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 25]), torch.Size([64, 25]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = next(iter(train_loader))\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3331a7ba-dc83-4310-9030-f31012aa104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_TOKEN = tokenizer.token_to_id('[SOS]')\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder.to(device)\n",
    "        self.decoder = decoder.to(device)\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, inputs, outputs, teacher_forcing_ratio=0.5):\n",
    "        \"\"\"\n",
    "        Encoder를 이용해 질문 문장의 특성을 추출한다.\n",
    "           이 특성을 Decoder의 initial hidden_state로, \n",
    "           initial input으로 [SOS] 토큰을 입력하여 순차적으로 답변을 생성한다.\n",
    "        Encoder는 한번에 특성추출을 진행된다.\n",
    "        Decoder는 time step 별로 순차적으로 진행된다.\n",
    "        \n",
    "        Parameter\n",
    "            inputs: 질문 batch data\n",
    "            outputs: 답변 batch data (teacher forcing 시 사용.)\n",
    "            teacher_forcing_ratio=0.5: float - 추론시 Teacher Forcing(정답을 다음 시점의 입력으로 넣는 것) 이 발생할 비율. \n",
    "        \"\"\"\n",
    "        # inputs : (batch_size, sequence_length) 질문\n",
    "        # outputs: (batch_size, sequence_length) 답변\n",
    "        \n",
    "        batch_size, output_length = outputs.shape\n",
    "        output_vocab_size = self.decoder.vocab_size\n",
    "        \n",
    "        # 리턴할 예측된 outputs를 저장할 임시 변수\n",
    "        #                      =>Decoder가 예측한 timestep별 단어를 저장.\n",
    "        # (sequence_length, batch_size, vocab_size)\n",
    "        predicted_outputs = torch.zeros(output_length, batch_size, output_vocab_size).to(self.device)\n",
    "        \n",
    "        ##############################################\n",
    "        # Encoder  처리\n",
    "        ###############################################\n",
    "        # output [seq_length, batch, hidden * 2] 양방향(* 2) ||| hidden (Bidirectional(2) x number of layers(1), batch_size, hidden_size)\n",
    "        encoder_output, encoder_hidden = self.encoder(inputs)\n",
    "\n",
    "\n",
    "        ###################################################\n",
    "        #  Decoder 처리\n",
    "        ################################################\n",
    "        ## encoder_output에서 마지막 timestep의 hidden이 \n",
    "        ####                      decoder에 입력할 초기 hidden_state (context vector 조회)\n",
    "        decoder_hidden = encoder_output[-1, :, :].unsqueeze(0)  # [seq_len, batch, hidden] 마지막 seq만 조회. 2차원이 되므로 seq_length 축 추가.\n",
    "        # [25, 64, 512] = [-1, :, :] => [64, 512] =seq_len 축 추가(unsqueeze)=> [1, 64, 512]\n",
    "       \n",
    "        # (batch_size) shape의 SOS TOKEN으로 채워진 Decoder 첫번째 timestep의 입력 생성\n",
    "        decoder_input = torch.full((batch_size,), fill_value=SOS_TOKEN, device=self.device)\n",
    "        \n",
    "        # 한개 토큰씩 순회하면서 출력 단어토큰을 생성\n",
    "        for t in range(0, output_length):\n",
    "            # decoder_input : 첫번째 입력은 (batch_size) 형태의 [SOS] TOKEN로 채워진 입력, 다음 부터는 생성된 token\n",
    "            # decoder_output: (batch_size, vocab_size)\n",
    "            # decoder_hidden: (Bidirectional(1) x number of layers(1), batch_size, hidden_size), context vector와 동일 shape\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "            # t번째 단어에 디코더의 output 저장\n",
    "            predicted_outputs[t] = decoder_output\n",
    "            \n",
    "            # teacher forcing 적용 여부 확률로 결정 (math.random.random(): 0 ~ 1 실수.)\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            # top1 단어 토큰 예측\n",
    "            top1 = decoder_output.argmax(1) \n",
    "            \n",
    "            # teacher forcing 인 경우 ground truth 값을, 그렇지 않은 경우, 예측 값을 다음 input으로 지정\n",
    "            decoder_input = outputs[:, t] if teacher_force else top1\n",
    "        \n",
    "        return predicted_outputs.permute(1, 0, 2) # (batch_size, sequence_length, vocab_size)로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65871f8b-6346-4b6e-a384-41ac3b86da80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e89fed5-b059-4371-b836-c3eb59bebdfb",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dac7b8a-935e-4f3a-9fa5-efbacbfc19d7",
   "metadata": {},
   "source": [
    "## 모델생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0280640f-243a-4413-8e8c-dc0285b7aaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 15579\n",
      "======================\n",
      "Seq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(15579, 200, padding_idx=0)\n",
      "    (gru): GRU(200, 512, bidirectional=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(15579, 200, padding_idx=0)\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "    (gru): GRU(200, 1024)\n",
      "    (classifier): Linear(in_features=1024, out_features=15579, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = dataset.vocab_size\n",
    "\n",
    "# 인코더 양방향 여부 (True)\n",
    "ENCODER_BIDIRECTIONAL = True\n",
    "##  인코더 GRU의 bidirectional=True 인 경우 hidden이 두배로 나온다. \n",
    "#   이게 Decoder에 입력되야 하므로 Decoder의 hidden_size는 인코더의 두배가 된다.\n",
    "ENCODER_HIDDEN_SIZE = 512 # 인코더의 hidden_size\n",
    "DECODER_HIDDEN_SIZE = ENCODER_HIDDEN_SIZE * 2 if ENCODER_BIDIRECTIONAL else ENCODER_HIDDEN_SIZE # Encoder를 양방향으로 한 경우 Decoder의 hidden 입력은 hidden_size * 2\n",
    "EMBEDDIMG_DIM = 200\n",
    "\n",
    "print(f'vocab_size: {VOCAB_SIZE}\\n======================')\n",
    "\n",
    "# Encoder 정의\n",
    "encoder = Encoder(vocab_size=VOCAB_SIZE, \n",
    "                  hidden_size=ENCODER_HIDDEN_SIZE, \n",
    "                  embedding_dim=EMBEDDIMG_DIM, \n",
    "                  num_layers=1,\n",
    "                  bidirectional=ENCODER_BIDIRECTIONAL)\n",
    "# Decoder 정의\n",
    "decoder = Decoder(vocab_size=VOCAB_SIZE, \n",
    "                  hidden_size=DECODER_HIDDEN_SIZE, \n",
    "                  embedding_dim=EMBEDDIMG_DIM, \n",
    "                  num_layers=1)\n",
    "\n",
    "# Seq2Seq 생성\n",
    "# encoder, decoder를 device 모두 지정\n",
    "model = Seq2Seq(encoder, decoder, device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba83263-e042-4579-9784-2403eb3c3fa1",
   "metadata": {},
   "source": [
    "## loss함수, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "839652a6-a4f0-4146-888b-30a9670854c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a659df1-87a2-4fe0-a095-e031ed130e68",
   "metadata": {},
   "source": [
    "## train/evaluation 함수 정의\n",
    "\n",
    "### train 함수정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "525cf939-c995-434c-bef0-fd607790090f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 25])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = next(iter(train_loader))\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7890cf94-0e55-497e-b12b-cf585ad09f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25 * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048ca8af-0556-4b59-a0ba-69f1995873aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, data_loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    loss_list = []\n",
    "    \n",
    "    for X, y in data_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X, y, teacher_forcing_ratio=0.5)\n",
    "        # pred shape: (batch_size, seq_length, vocab_size:단어별확률이므로)  \n",
    "        #            ex) (64, 25, 어휘수)\n",
    "        \n",
    "        yhat = pred.reshape(-1, pred.size(2))  # (batch * seq_len, 어휘수), (64*25, 15000)\n",
    "\n",
    "        # 정답 shape변경\n",
    "        # (batch_size*sequence_length) 로 변경 (64, 25) =>                  (64*25, )\n",
    "        y = y.reshape(-1)           \n",
    "        \n",
    "        # Loss 계산\n",
    "        loss = loss_fn(yhat, y)\n",
    "        # gradient 계산\n",
    "        loss.backward()\n",
    "        #파라미터 업데이트\n",
    "        optimizer.step()\n",
    "        # gradient 초기화\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "    return np.mean(loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8981388d-ad33-4318-844b-29a5a434d2a7",
   "metadata": {},
   "source": [
    "### Test 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "52e0f5d3-dcdc-4b8e-b359-99aa8391e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fn(model, data_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    \n",
    "    loss_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X, y)\n",
    "            \n",
    "            yhat = pred.reshape(-1, pred.shape[2])\n",
    "            y = y.reshape(-1)\n",
    "            \n",
    "            # Loss 계산\n",
    "            loss = loss_fn(yhat, y)\n",
    "            \n",
    "            loss_list.append(loss.item())\n",
    "            \n",
    "    return np.mean(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5326e1fa-7821-4d5e-9118-1b60c12c8db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a71e20c-8a03-44f4-bbbc-8f4e51b85636",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335aa2c8-4e29-46dd-90bd-69a41301adf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# 학습은 GPU에서 해야 합니다. colab을 이용하세요\n",
    "##########################################\n",
    "import time\n",
    "\n",
    "EPOCHS = 10\n",
    "MODE_PATH = 'models/seq2seq-chatbot-model.pt'\n",
    "\n",
    "best_loss = np.inf\n",
    "s = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    loss = train_fn(model, train_loader, optimizer, loss_fn, device)\n",
    "    \n",
    "    val_loss = test_fn(model, test_loader, loss_fn, device)\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model, MODE_PATH)\n",
    "        print(f\"[{epoch+1} epoch 에서 저장]\")\n",
    "    \n",
    "    if epoch % 5 == 0 or epoch == EPOCHS-1:\n",
    "        print(f'epoch: {epoch+1}, loss: {loss:.4f}, val_loss: {val_loss:.4f}')\n",
    "\n",
    "e = time.time()\n",
    "print(e-s, \"초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf61c71e-3bbb-4a8b-8681-1dce2e4758f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fe0585a-eb35-47dd-88bf-276d749f5f00",
   "metadata": {},
   "source": [
    "# 결과확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e4bcf956-b7e1-4f05-bd96-723fe0624339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import SubsetRandomSampler \n",
    "\n",
    "\n",
    "def handle_special_tokens(decoded_string):\n",
    "    \"\"\"\n",
    "    Subword 처리\n",
    "    subword는 단어의 시작으로 쓰인 것과 중간 부분에 사용된 두가지 subword가 있다. 중간에 쓰인 subword는 `#`과 같은 특수문자로 시작 한다.\n",
    "    tokenizer.decode() 결과 문자열은 subword의 특수문자('#')을 처리하지 않는다. 이것을 처리하는 함수\n",
    "    ex) \"이 기회 #는 내 #꺼 #야\" ==> \"이 기회는 내꺼야\"\n",
    "    \n",
    "    Parameter\n",
    "        decoded_string: str - Tokenizer가 decode한 중간 subword의 특수문자 처리가 안된 문자열. \n",
    "    Return\n",
    "        str: subword 특수문자 처리한 문자열\n",
    "    \"\"\"\n",
    "    tokens = decoded_string.split()\n",
    "    \n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.startswith('#'):\n",
    "            if new_tokens: # 리스트에 토큰이 이미 있으면 마지막 토큰 뒤에 붙인다.  new_token[-1]을 조회해 그 뒤에 합친다. (#은 지우고)\n",
    "                new_tokens[-1] += token[1:]\n",
    "            else: # 첫번째 토큰일 경우는 그냥 #을 지우고 append한다. (첫 토큰으로 subword가 나올 수있기 때문에.)\n",
    "                new_tokens.append(token[1:])\n",
    "        else:\n",
    "            new_tokens.append(token)\n",
    "    return ' '.join(new_tokens)\n",
    "\n",
    "# dataset에서 일부 데이터들을 가지고 확인\n",
    "def random_evaluation(model, dataset, device, n=10):\n",
    "    \"\"\"\n",
    "    Dataset에서 일부 질문-답변 쌍들을 가져다 모델에 질문을 넣어 추론한 결과와 함께 확인.\n",
    "    Parameter\n",
    "        model: 학습된 seq2seq 모델\n",
    "        dataset: 질문-답변 쌍울 추출할 dataset\n",
    "        device\n",
    "        n: int - 추출할 질문-답변 쌍 개수 default: 10\n",
    "    \"\"\"\n",
    "    n_samples = len(dataset)         # 총 데이터수\n",
    "    indices = list(range(n_samples)) # index list\n",
    "    np.random.shuffle(indices)      # Shuffle\n",
    "    sampled_indices = indices[:n]   # n개 index\n",
    "    \n",
    "    # 샘플링한 데이터를 기반으로 DataLoader 생성\n",
    "    ### DataLoader의 Sampler -> batch size만큼 Dataset에서 Data를 조회하는 방법을 정의한 객체.\n",
    "    sampler = SubsetRandomSampler(sampled_indices) # index를 주면 그 index의 데이터들만 조회.\n",
    "    sampled_dataloader = DataLoader(dataset, batch_size=10, sampler=sampler) \n",
    "    # sampler를 제공하면 그 sampler를 이용해 Dataset으로 부터 batch 개수 만큼 가져와 제공.\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in sampled_dataloader:\n",
    "            X, y = X.to(device), y.to(device)        \n",
    "            output = model(X, y, teacher_forcing_ratio=0) #추론 -> teacher forcing: 0\n",
    "            # output: (number of samples, sequence_length, vocab_size)\n",
    "            \n",
    "            preds = output.cpu().numpy()  # to(\"cpu\") == cpu()  (batch, seq, 총단어수)\n",
    "            X = X.cpu().numpy()\n",
    "            y = y.cpu().numpy()\n",
    "            \n",
    "            for i in range(n):\n",
    "                print(f'질문   : {handle_special_tokens(tokenizer.decode(X[i]))}')\n",
    "                print(f'답변   : {handle_special_tokens(tokenizer.decode(y[i]))}')\n",
    "                print(f'예측답변: {handle_special_tokens(tokenizer.decode(preds[i].argmax(1)))}')  \n",
    "                # pred[i] 한개 문장. (seq, 단어수) 단어수 기준 max index조회하면 각 seq의 token_id 배열이 나온다.\n",
    "                print('==='*10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "850e8b2b-29c8-40ef-8abf-94e53b737cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'헤어진지 한달 .'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(a[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d89b1e-c708-4943-8c44-24f3bb21939e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b15111-91d7-426f-a47b-24b031d1605e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de024919-1a91-4ae1-866a-d364408e8aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060d38ad-be9f-4127-a220-32970448beeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bc65a4-5082-4df5-90a6-6d26154698dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "MODE_PATH = 'models/seq2seq-chatbot-model.pt'\n",
    "load_model = torch.load(MODE_PATH, map_location=device)\n",
    "random_evaluation(load_model, test_set, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "513d1d03-f5bb-4214-9e8a-089614f004bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'헤어진지 한달 .'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827215a2-7bdb-44c5-b891-8ff15ae621f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc2920e-fcdb-47d3-a61d-14c61ddb6809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
