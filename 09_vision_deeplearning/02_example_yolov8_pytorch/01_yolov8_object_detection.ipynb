{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c408c92e",
   "metadata": {},
   "source": [
    "# [YOLOv8](https://docs.ultralytics.com/)\n",
    "\n",
    "## 설치\n",
    "\n",
    "- `pip install ultralytics`\n",
    "- 주피터노트북에서 실행할 경우 프로그래스바를 실행하기 위해서 다음을 설치한다. (필수는 아님)\n",
    "    - `pip install ipywidgets` or `conda install -y -c conda-forge ipywidgets`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f3d95a",
   "metadata": {},
   "source": [
    "## 실행 방법\n",
    "- CLI (command line interface)에서 터미널 명령어로 추론/평가/학습을 진행할 수 있다.\n",
    "    - 모델이 처리한 결과를 최종결과로 사용할 경우 이 방법으로 처리한다.\n",
    "- Python lib 를 이용해 코드상에 원하는 추론/평가/학습을 진행할 수 있다.\n",
    "    - 모델이 처리한 결과를 받아서 추가 작업이 필요한 경우 이 방법으로 처리한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbfe070",
   "metadata": {},
   "source": [
    "# CLI 기본 명령어 구조\n",
    "\n",
    "- 구문\n",
    "    - <span style='font-size:1.3em'>**yolo**  **task**=detect|classify|segment|pose  **mode**=train|val|predict  **model**=yolov8n.yaml|yolov8n.pt|..  **args**</span>\n",
    "    - <b style='font-size:1.2em'>task:</b> \\[detect, classify, segment, pose\\] 중 하나를 지정한다. \\[optional\\]로 생략하면 모델을 보고 추측해서 task를 정한다.\n",
    "        - **detect:** Object detection\n",
    "        - **classify:** Image classification\n",
    "        - **segment:** Instance segmentation\n",
    "        - **pose:** pose estimation\n",
    "    - <b style='font-size:1.2em'>mode:</b> \\[train, val, predict, export\\] 중 하나를 지정한다. \\[필수\\]로 입력해야 한다.\n",
    "        - **train:** custom dataset을 train 시킨다.\n",
    "        - **val:** 모델 성능을 평가한다.\n",
    "        - **predict:** 입력 이미지에 대한 추론을 한다.\n",
    "        - **export:** 모델을 다른 형식으로 변환한다.\n",
    "    - <b style='font-size:1.2em'>model:</b> **pretrained 모델**이나 **모델 설정 yaml 파일**의 경로를 설정한다. \\[필수\\]로 입력해야 한다.\n",
    "        - pretrained 모델 파일경로\n",
    "            - task에 맞는 pretrained 모델파일의 저장 경로를 지정한다.\n",
    "            - transfer learnging을 하거나 fine tuning 시 방법\n",
    "        - 모델 구조 설정 yaml 파일 경로\n",
    "            - task에 맞는 pretrained 모델 설정파일(yaml파일)의 경로를 지정한다.\n",
    "            - train mode에서 지정하며 모델을 새로 생성해서 처음부터 학습 시킬 경우 지정한다.\n",
    "        - Ultralytics에서 제공하는 Pretrained 모델\n",
    "            - 모델 크기에 따라 5개의 모델을 제공하며 큰 모델은 작은 모델에 비해 추론 성능이 좋은대신 속도는 느리다.\n",
    "            - 모델은 처음 추론또는 학습할때 local 컴퓨터에 없으면 download 받는다.\n",
    "            - https://github.com/ultralytics/ultralytics#models\n",
    "            - ### 제공 모델\n",
    "            \n",
    "            | **task\\\\모델크기**  | **nano**   | **small** | **medium** | **large** | **xlarge** |\n",
    "            |:--------------------|------------|-------------|------------|-----------|----------|\n",
    "            | **object detection**| yolov8n    | yolov8s     | yolov8m    | yolov8l   | yolov8x    |\n",
    "            | **segmentation**   | yolov8n-seg  | yolov8s-seg     | yolov8m-seg    | yolov8l-seg   | yolov8x-seg    |\n",
    "            | **classification** | yolov8n-cls  | yolov8s-cls     | yolov8m-cls    | yolov8l-cls   | yolov8x-cls    |  \n",
    "            | **pose estimation** | yolov8n-pose  | yolov8s-pose     | yolov8m-pose    | yolov8l-pose   | yolov8x-pose    | \n",
    "            \n",
    "            \n",
    "            - 확장자가 `pt`이면 pretrained 된 모델을, `yaml`이면 모델 구조 설정파일을 download하여 실행한다.\n",
    "                - pretrained model은 fine tuning이나 추론할 때, yaml설정파일은 처음부터 학습할 경우 설정하여 받는다.\n",
    "    - <b style='font-size:1.2em'>args:</b> task와 mode과 관련한 추가 설정값들을 지정한다.\n",
    "        - https://docs.ultralytics.com/cfg/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7e10cd",
   "metadata": {},
   "source": [
    "# [Object Detection](https://docs.ultralytics.com/tasks/detection/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca360a0",
   "metadata": {},
   "source": [
    "##  Predict (추론)\n",
    "\n",
    "### 모델로딩\n",
    "- Ultralytics에서 제공하는 Pretrained Model이나 직접 학습시킨 모델을 이용해 추론한다.\n",
    "- Ultralytics는 Object Detection을 위한 [Pretrained 모델](#제공-모델)을 제공한다.\n",
    "    - Object Detection 모델은 COCO dataset으로 학습되었다.\n",
    "    - 모델 명을 지정하면 자동으로 다운로드를 받는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8235d4bc",
   "metadata": {},
   "source": [
    "### CLI\n",
    "`yolo task=detect mode=predict model=model_path source=추론할_image_path`\n",
    "- 추가 설정 (configuration)\n",
    "    - https://docs.ultralytics.com/usage/cfg/#predict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1ac700-b1ce-44a5-900a-999e40017603",
   "metadata": {},
   "source": [
    "> - argument 설정은 `name=value` 형식으로 한다. (`--name value`나 `name value` 는 안된다.)\n",
    "\n",
    "> ### 추론 할 Source 타입\n",
    "> - https://docs.ultralytics.com/modes/predict/#inference-sources\n",
    "> - **Image:** 이미지파일경로, URL, PIL.Image, np.ndarray, torch.Tensor\n",
    "> - **동영상:** 동영상파일경로, 웹캠 ID, 유튜브 URL\n",
    "> - **여러개의 영상처리:** 디렉토리 경로 또는 경로들을 원소로 가지는 리스트."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcc01ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b0f28a7",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb48e01f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f33daef5",
   "metadata": {},
   "source": [
    "### 한번에 여러장 추론\n",
    "- 추론한 이미지들이 **같은 경로(Path)에** 있을 경우 **그 디렉토리의 경로를 문자열로 전달한다.**\n",
    "- **wild card 문자** 를 이용해 특정 확장자의 파일이나 특정 문자열을 포함한 파일들을 추론할 수있다.\n",
    "    - \\*: 파일명에 지정하며 n 글자를 표현한다.\n",
    "    - \\*\\*: 디렉토리에 지정하면 모든 하위 디렉토리를 표현한다.\n",
    "- 추론할 이미지들이 **서로 다른 경로에** 있을 경우 **리스트에 경로들을 모아서 전달한다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9373630b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17320e83",
   "metadata": {},
   "source": [
    "## 동영상\n",
    "- source에 동영상 파일 경로를 지정한다.\n",
    "    - frame 단위로 추론한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71e8669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcd00d48",
   "metadata": {},
   "source": [
    "## 추론결과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ea25ad",
   "metadata": {},
   "source": [
    "### ultralytics.yolo.engine.results.Results\n",
    "- 모델의 추론 결과는 list에 이미지별 예측결과를 Results에 담아 반환한다.\n",
    "- **Results** : 한개 이미지에 대한 추론결과를 담는 객체\n",
    "- 추론 종류에 따라 다음 속성을 이용해 결과를 조회한다.\n",
    "    - Detection: **`result.boxes`** - Boxes type\n",
    "    - Segmentation: **`result.masks`** - Masks type\n",
    "    - Classification: **`result.probs`** - Probs type\n",
    "    - Pose estimator: **`result.keypoints`** - Keypoints  type\n",
    "- **Boxes, Masks, Keypoints 는 모두 iteratble 타입으로 for in 문으로 찾은 개별 물체에 대한 결과를 같은 타입의 instance로 조회할 수 있다.**    \n",
    "- 추가 정보\n",
    "    - **Results.orig_img:** 추론한 원본 이미지\n",
    "    - **Results.orig_shape:** 추론한 원본 이미지의 크기 (height, width)\n",
    "    - **Results.path:** 추론한 원본이미지의 경로\n",
    "    - **Results.names:** class2classname 정의한 딕셔너리 (key: 클래스, name: 클래스 이름)\n",
    "- 메소드\n",
    "    - **Results.plot()**\n",
    "        - 원본 이미지에 추론한 결과를 표시한 이미지를 반환한다.\n",
    "        - OpenCV를 이용해 처리한 이미지가 반환되어 **BGR 색모드의 ndarray로 반환** 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02964b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2825ee77",
   "metadata": {},
   "source": [
    "### Object Detection 결과값 조회\n",
    "\n",
    "- ultralytics.yolo.engine.results.**Boxes**에 추론 결과를 담아 반환\n",
    "    - Results.boxes로 조회\n",
    "- 주요 속성\n",
    "    - shape: 결과 shape. (찾은 물체개수, 6)\n",
    "    - boxes\n",
    "        - 6: 좌상단 x, 좌상단 y, 우하단 x, 우하단 y, confidence score, label\n",
    "    - xyxy\n",
    "        - bounding box의 `좌상단 x, 좌상단 y, 우하단 x, 우하단 y` 좌표 반환\n",
    "    - xyxyn\n",
    "        - xyxy를 이미지 대비 비율로 반환\n",
    "    - xywh\n",
    "        - bounding box의 `center x, center y, 너비, 높이` 를 반환\n",
    "    - xywhn\n",
    "        - xywh를 이미지 대비 비율로 반환\n",
    "    - cls: 찾은 물체의 label\n",
    "    - conf: cls에 대한 confidence score (그 물체일 확률)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> - 0차원 torch.Tensor 를 상수로 변환\n",
    ">     - `tensor.item()`\n",
    "> - N차원 torch.Tensor를 ndarray로 변환\n",
    ">     - `tensor.numpy()`\n",
    ">     - Tensor객체가 GPU메모리에 있을 경우 메인메모리(CPU)로 먼저 옮겨야 한다.\n",
    ">         - `tensor.to('cpu')` or `tensor.cpu()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecc8384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cb0518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1410bf07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dd2390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfbdf29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7617db64",
   "metadata": {},
   "source": [
    "# TODO\n",
    "Web Cam으로 입력받은 frame에서 detect 한 결과에 bounding box + class name + 확률을 출력해서 실시간으로 보여준다.  \n",
    "> `yolo task=detect mode=predict model=yolov8s.pt source=0` 한 결과와 같이 나오도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d97b53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "d6bb26803bcea62f49e4c67963aa289be587a14c784102c9499967ce94407a08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
