{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide\n",
    "\n",
    "1. **주의**  LinearRegression은 random_state 가 없다.\n",
    "1. 선행회귀에서 각각 모델을 언제사용?\n",
    "\t- **under fitting**\n",
    "\t\t- y값을 만들기 위한 Feature가 적어서 y값에 적합한 계산식을 만들수 없는 경우다. (2차함수 3차 함수등이 이런 예이다. )\n",
    "\t\t\t- 이런 것이 noise 개념이다. 예를 들어 두사람이 나이가 20세인데 한사람은 물건을 1개, 다른사람음 100개를 샀다. 그럼 나이라는 feature를 가지고 y에 대해 설명을 할 수 없다. 즉 구매량 차이에 영향을 주는 다른 Feature(설명변수)가 있는데 그것을 수집하지 못한 것이다. \n",
    "\t\t- 그래서 feature를 늘린다. 그런데 임의로 늘릴 수 없으니 기존 컬럼들을 이용해 늘린다. (교차곱항, 다차항을 만든다.)\n",
    "\t\t\n",
    "\t- **over fiiting**\n",
    "\t\t- 위와 반대의 상황\n",
    "\t\t- y값을 만들기 위한 계산식에 쓰일 feature가 너무 많아서 (예를 들어 선형의 개형을 가진 데이터셋인데 feature가 많아 3차 5차 함수의 형태가 나온다면 오히려 문제가 된다. train에 맞추겠지만 (여러번 꺽어서) 이상치 영향도 많이 받고 해서 일반화가 안된다.\n",
    "\t\t- 그럼 컬럼을 줄여야 한다.\n",
    "\t\t- 어떻게 => y와 연관성 없는 feature들을 제거한다. (이건 도메인 지식필요)\n",
    "\t\t- 통계적으로 상관관계 보고 제거\n",
    "\t\t- 머신러닝: Ridge, Lasso 규제를 이용해 Feature에 곱하는 weight를 0에 가깝게 만들어 영향력을 줄인다.\n",
    "\t\t\n",
    "1. X: 기온, y:월드콘 판매량 으로 설명       \n",
    "\t- X1-기온, X2: 광고 y: 판매량=> 각 feature의 영향력=> 가중치 W1, W2      \n",
    "\t- ax + b : 선형관계=> 가설(통계)==>ML에선 알고리즘. a, b를 찾고 그것의 유의성 설명(통계), ML - 찾아서 예측하기.    \n",
    "\t- 단순/다중 선형회귀 이야기도 한다.   \n",
    "\n",
    "1. 보스톤데이터셋에서  CHAS Feature 원핫인코딩하지 않는다. dummy 변수로 이미 인코딩되있는 형태다. \n",
    "1. - 다항회귀를 설명할 때 선형, 비선형 이야기 **강조** 하지 말자. (설명중에 간단히)\n",
    "1.  잡음 이야기 하면서 성능이 안나오는 것은 우리가 Feature가 부족해서 그렇다. Feature를 늘려야 하는데 데이터를 더 모을 수 없으므로 파생변수를 만들어 Feature를 늘린다. Feature가 늘어나면 LinearREgression은 모델이 복잡해 진다. (WX + B => WX1 + Wx2 + Wx3 + b 식으로 식이 복잡해 지므로) 그래서 성능이 올라간다. \n",
    "1.  파생변수를 만드는 방법 중 Polynomial Features를 사용하면 기존 Feature를 N 제곱한 값을 가지는 Feature를 늘릴 수 있다. \n",
    "1. 결국 다항회귀는 비선형 데이터에 대한 패턴을 찾아 성능을 높이는 것.\n",
    "1. 규제의 alpha변경에 따른 weight 변화할때\n",
    "\t- 그래프 그리지 말자.\n",
    "\t- dataframe에 그냥 ndarray(ridge.coef_) 한 값 넣자. (Series만들지 말고)\n",
    "1. 규제 정리\n",
    "\t- TODO: 여기 쓴 것 정리해서 추가/변경\n",
    "\t- Feature가 너무 많아서 Overfitting 발생->Feature를 줄여줄 필요가 있다.\n",
    "\t- 규제\n",
    "\t\t- Feature를 줄여주기 위해 X를 바꿀 수 없으니 W를 바꿔야 한다. W를 0에 가깝게 하면 X의 영향력이 줄어드니 Feature를 줄여주는 효과가 있다.\n",
    "\t\t- 어떻게?\n",
    "\t\t- 오차에 W의 합계를 더한다. 그래서 오차를 더크게 한다. 그러면 **W가 크면 오차가 커지네** 라고 모델이 생각하므로 W를 0에 가까워지도록 만들어 주게 된다.(개념)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 선형회귀 개요\n",
    "\n",
    "선형 회귀(線型回歸, Linear regression)는 종속 변수 y와 한 개 이상의 독립 변수X와의 선형 상관 관계를 모델링하는 회귀분석 기법. [위키백과](https://ko.wikipedia.org/wiki/%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## 선형회귀 모델\n",
    "- 각 Feature들에 가중치(Weight)를 곱하고 편향(bias)를 더해 예측 결과를 출력한다.\n",
    "- Weight와 bias가 학습 대상 Parameter가 된다.\n",
    "\n",
    "$$\n",
    "\\hat{y_i} = w_1 x_{i1} + w_2 x_{i2}... + w_{p} x_{ip} + b\n",
    "\\\\\n",
    "\\hat{y_i} = \\mathbf{w}^{T} \\cdot \\mathbf{X} \n",
    "$$\n",
    "\n",
    "- $\\hat{y_i}$: 예측값\n",
    "- $x$: 특성(feature-컬럼)\n",
    "- $w$: 가중치(weight), 회귀계수(regression coefficient). 특성이 $\\hat{y_i}$ 에 얼마나 영향을 주는지 정도\n",
    "- $b$: 절편\n",
    "- $p$: p 번째 특성(feature)/p번째 가중치\n",
    "- $i$: i번째 관측치(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Boston DataSet\n",
    "보스톤의 지역별 집값 데이터셋\n",
    "\n",
    " - CRIM\t: 지역별 범죄 발생률\n",
    " - ZN\t: 25,000 평방피트를 초과하는 거주지역의 비율\n",
    " - INDUS: 비상업지역 토지의 비율\n",
    " - CHAS\t: 찰스강에 대한 더미변수(강의 경계에 위치한 경우는 1, 아니면 0)\n",
    " - NOX\t: 일산화질소 농도\n",
    " - RM\t: 주택 1가구당 평균 방의 개수\n",
    " - AGE\t: 1940년 이전에 건축된 소유주택의 비율\n",
    " - DIS\t: 5개의 보스턴 고용센터까지의 접근성 지수\n",
    " - RAD\t: 고속도로까지의 접근성 지수\n",
    " - TAX\t: 10,000 달러 당 재산세율\n",
    " - PTRATIO : 지역별 교사 한명당 학생 비율\n",
    " - B\t: 지역의 흑인 거주 비율\n",
    " - LSTAT: 하위계층의 비율(%)\n",
    " \n",
    " - MEDV\t: Target.  지역의 주택가격 중앙값 (단위: $1,000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boston housing dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LinearRegression\n",
    "- 가장 기본적인 선형 회귀 모델\n",
    "- 각 Feauture에 가중합으로 Y값을 추론한다.\n",
    "- attribute(학습 후 조회가능)\n",
    "    - **coef_**: 각 Feature에 곱하는 가중치\n",
    "    - **intercept_**: y절편. 모든 Feature가 0일때 예측값\n",
    "    \n",
    "### 데이터 전처리\n",
    "\n",
    "- **선형회귀 모델사용시 전처리**\n",
    "    - **범주형 Feature**\n",
    "        - : 원핫 인코딩\n",
    "    - **연속형 Feature**\n",
    "        - Feature Scaling을 통해서 각 컬럼들의 값의 단위를 맞춰준다.\n",
    "        - StandardScaler를 사용할 때 성능이 더 잘나오는 경향이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### train/test set 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-16T05:43:20.067827Z",
     "start_time": "2022-12-16T05:43:20.051167Z"
    },
    "execution": {
     "iopub.execute_input": "2022-12-13T00:54:52.354753Z",
     "iopub.status.busy": "2022-12-13T00:54:52.354753Z",
     "iopub.status.idle": "2022-12-13T00:54:52.363755Z",
     "shell.execute_reply": "2022-12-13T00:54:52.362752Z",
     "shell.execute_reply.started": "2022-12-13T00:54:52.354753Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### 모델 생성, 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T02:53:53.375962Z",
     "start_time": "2021-11-22T02:53:53.353025Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "> ### Coeficient의 부호\n",
    "> - weight가 \n",
    "> - 양수: Feature가 1 증가할때 y(집값)도 weight만큼 증가한다.\n",
    "> - 음수: Feature가 1 증가할때 y(집값)도 weight만큼 감소한다.\n",
    "> - 절대값 기준으로 0에 가까울 수록 집값에 영향을 주지 않고 크면 클수록(0에서 멀어질 수록) 집값에 영향을 많이 주는 Feature 란 의미가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 다항회귀 (Polynomial Regression)\n",
    "- 전처리방식 중 하나로 Feature가 너무 적어 y의 값들을 다 설명하지 못하여 underfitting이 된 경우 Feature를 늘려준다.\n",
    "- 각 Feature들을 거듭제곱한 것과 Feature들 끼리 곱한 새로운 특성들을 추가한다.\n",
    "    - 파라미터(Coef, weight)를 기준으로는 일차식이 되어 선형모델이다. 그렇지만 input 기준으로는 N차식이 되어 비선형 데이터를 추론할 수 있는 모델이 된다.\n",
    "- `PolynomialFeatures` Transformer를 사용해서 변환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T13:23:44.707240Z",
     "start_time": "2023-02-07T13:23:44.695238Z"
    },
    "execution": {
     "iopub.execute_input": "2022-12-13T01:56:41.036650Z",
     "iopub.status.busy": "2022-12-13T01:56:41.036650Z",
     "iopub.status.idle": "2022-12-13T01:56:41.047406Z",
     "shell.execute_reply": "2022-12-13T01:56:41.046883Z",
     "shell.execute_reply.started": "2022-12-13T01:56:41.036650Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1) (100,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def func(X):\n",
    "    return X**2 + X + 2 + np.random.normal(0,1, size=(X.size, 1))\n",
    "\n",
    "m = 100\n",
    "X = 6 * np.random.rand(m, 1) - 3\n",
    "y = func(X)\n",
    "y = y.flatten()\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 모델생성, 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### PolynomialFeatures를 이용해 다항회귀구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### LinearRegression 모델을 이용해 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## degree를 크게\n",
    "- Feature가 너무 많으면 Overfitting 문제가 생긴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### PolynomialFeatures 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### PolynomialFeatures를 Boston Dataset에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 모델 생성 학습 추론 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 규제 (Regularization)\n",
    "- 선형 회귀 모델에서 과대적합(Overfitting) 문제를 해결하기 위해 가중치(회귀계수)에 페널티 값을 적용한다.\n",
    "- 입력데이터의 Feature들이 너무 많은 경우 Overfitting이 발생.\n",
    "    - Feature수에 비해 관측치 수가 적은 경우 모델이 복잡해 지면서 Overfitting이 발생한다.\n",
    "- 해결\n",
    "    - 데이터를 더 수집한다. \n",
    "    - Feature selection\n",
    "        - 불필요한 Features들을 제거한다.\n",
    "    - 규제 (Regularization) 을 통해 Feature들에 곱해지는 가중치가 커지지 않도록 제한한다.(0에 가까운 값으로 만들어 준다.)\n",
    "        - LinearRegression의 규제는 학습시 계산하는 오차를 키워서 모델이 오차를 줄이기 위해 가중치를 0에 가까운 값으로 만들도록 하는 방식을 사용한다.\n",
    "        - L1 규제 (Lasso)\n",
    "        - L2 규제 (Ridge)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ridge Regression (L2 규제)\n",
    "- 손실함수(loss function)에 규제항으로 $\\alpha \\sum_{i=1}^{n}{w_{i}^{2}}$ (L2 Norm)을 더해준다.\n",
    "- $\\alpha$는 하이퍼파라미터로 모델을 얼마나 많이 규제할지 조절한다. \n",
    "    - $\\alpha = 0$ 에 가까울수록 규제가 약해진다. (0일 경우 선형 회귀동일)\n",
    "    - $\\alpha$ 가 커질 수록 모든 가중치가 작아져 입력데이터의 Feature들 중 중요하지 않은 Feature의 예측에 대한 영향력이 작아지게 된다.\n",
    "\n",
    "$$\n",
    "\\text{손실함수}(w) = \\text{MSE}(w) + \\alpha \\cfrac{1}{2}\\sum_{i=1}^{n}{w_{i}^{2}}\n",
    "$$\n",
    "\n",
    "> **손실함수(Loss Function):** 모델의 예측한 값과 실제값 사이의 차이를 정의하는 함수로 모델이 학습할 때 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 규제 alpha 에 따른 weight 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lasso(Least Absolut Shrinkage and Selection Operator) Regression (L1 규제)\n",
    "\n",
    "- 손실함수에 규제항으로 $\\alpha \\sum_{i=1}^{n}{\\left| w_i \\right|}$ (L1 Norm)더한다.\n",
    "- Lasso 회귀의 상대적으로 덜 중요한 특성의 가중치를 0으로 만들어 자동으로 Feature Selection이 된다.\n",
    "\n",
    "$$\n",
    "\\text{손실함수}(w) = \\text{MSE}(w) + \\alpha \\sum_{i=1}^{n}{\\left| w_i \\right|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PolynormialFeatures로 전처리한 Boston Dataset 에 Ridge, Lasso 규제 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### LinearRegression으로 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### Ridge 의 alpha값 변화에 따른 R square 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### lasso 의 alpha값 변화에 따른 R square 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ElasticNet(엘라스틱넷)\n",
    "- 릿지와 라쏘를 절충한 모델.\n",
    "- 규제항에 릿지, 라쏘 규제항을 더해서 추가한다. \n",
    "- 혼합비율 $r$을 사용해 혼합정도를 조절\n",
    "- $r=0$이면 릿지와 같고 $r=1$이면 라쏘와 같다.\n",
    "\n",
    "$$\n",
    "\\text{손실함수}(w) = \\text{MSE}(w) + r\\alpha \\sum_{i=1}^{n}{\\left| w_i \\right|}  + \\cfrac{1-r}{2}\\alpha\\sum_{i=1}^{n}{w_{i}^{2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 정리\n",
    "- 일반적으로 선형회귀의 경우 어느정도 규제가 있는 경우가 성능이 좋다.\n",
    "- 기본적으로 **Ridge**를 사용한다.\n",
    "- Target에 영향을 주는 Feature가 몇 개뿐일 경우 특성의 가중치를 0으로 만들어 주는 **Lasso** 사용한다. \n",
    "- 특성 수가 학습 샘플 수 보다 많거나 feature간에 연관성이 높을 때는 **ElasticNet**을 사용한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
